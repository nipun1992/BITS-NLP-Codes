{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "https://wordnet.princeton.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Chetana\n",
    "# NLTK provides direct access to wordnet. \n",
    "# WordNet corpus reader gives access to the Open Multilingual WordNet.\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag,word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import wordnet from the NLTK\n",
    "from nltk.corpus import wordnet \n",
    "# A synset is identified with a 3-parts of the form: word.pos.nn (word.part-of-speech.no.-of-sense)\n",
    "synset = wn.synsets(\"education\")\n",
    "print('Word and Type : ' + synset[1].name())\n",
    "print('The meaning of the word : ' + synset[0].definition())\n",
    "print('Example : ' + str(synset[0].examples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n",
      "['he needs a car to get to work']\n"
     ]
    }
   ],
   "source": [
    "# For a word like \"car\" we can take a look at the synsets:\n",
    "print(wn.synsets('car'))\n",
    "\n",
    "# Example usage of synset for \"car\":\n",
    "print(wn.synset('car.n.01').examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hear.v.01')]\n"
     ]
    }
   ],
   "source": [
    "#An entailment is an implication.\n",
    "#For example, looking implies seeing. \n",
    "#Buying implies choosing and paying. We can find entailments as seen below in the code.\n",
    "print(wn.synset('listen.v.01').entailments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('internet.n.01')]\n",
      "['internet', 'net', 'cyberspace']\n"
     ]
    }
   ],
   "source": [
    "# One primary use for WordNet is to determine the similarity between words.\n",
    "# Take for example the following two sentences:\n",
    "# 1. I learned natural language processing by resources found on the internet.\n",
    "# 2. I learned natural language processing by resources found on the net.\n",
    "\n",
    "# Both sentence 1. and 2. are the same, with the exception of the last word.\n",
    "# The words \"internet\" and \"net\" are synoynms, so the meaning of each sentence\n",
    "# is the same irrespective of whether \"internet\" or \"net\" is used at the end.\n",
    "\n",
    "# We can use the wordnet module to determine the synsets (synonym sets) of\n",
    "# the word internet:\n",
    "print(wn.synsets('internet'))\n",
    "\n",
    "# The entry 'internet.n.01' is a synset for the word internet.\n",
    "# Each synonym in the set is referred to as a **lemma**.\n",
    "# We can print out the list of such synsets and their corresponding\n",
    "# lemmas.(Specifically, the pairing of a synset with a word is called a lemma):\n",
    "print(wn.synset('internet.n.01').lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to WordNet, the word \"internet\" is a synonym of the word \"net\" and the word \"cyberspace\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: ['good', 'good', 'goodness', 'good', 'goodness', 'commodity', 'trade_good', 'good', 'good', 'full', 'good', 'good', 'estimable', 'good', 'honorable', 'respectable', 'beneficial', 'good', 'good', 'good', 'just', 'upright', 'adept', 'expert', 'good', 'practiced', 'proficient', 'skillful', 'skilful', 'good', 'dear', 'good', 'near', 'dependable', 'good', 'safe', 'secure', 'good', 'right', 'ripe', 'good', 'well', 'effective', 'good', 'in_effect', 'in_force', 'good', 'good', 'serious', 'good', 'sound', 'good', 'salutary', 'good', 'honest', 'good', 'undecomposed', 'unspoiled', 'unspoilt', 'good', 'well', 'good', 'thoroughly', 'soundly', 'good']\n"
     ]
    }
   ],
   "source": [
    "# Get Synonyms and Antonyms\n",
    "syn = list()\n",
    "ant = list()\n",
    "for synset in wn.synsets(\"good\"):\n",
    "   for lemma in synset.lemmas():\n",
    "      syn.append(lemma.name())    #add the synonyms\n",
    "      if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "        ant.append(lemma.antonyms()[0].name())\n",
    "      \n",
    "print('Synonyms: ' + str(syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonyms: ['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
     ]
    }
   ],
   "source": [
    "print('Antonyms: ' + str(ant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyponym and Hypernym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01'), Synset('cat.v.01'), Synset('vomit.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# Hyponym: \"a word of more specific meaning than a general or superordinate\n",
    "# term applicable to it. For example, spoon is a hyponym of cutlery.\"\n",
    "\n",
    "# First obtain the synsets for the term \"cat\":\n",
    "print(wn.synsets('cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n"
     ]
    }
   ],
   "source": [
    "# There are a few different synsets for this word.\n",
    "# Let us take a look at what the definition of\n",
    "# the synset 'cat.n.01' is:\n",
    "print(wn.synset('cat.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domestic_cat\n",
      "house_cat\n",
      "Felis_domesticus\n",
      "Felis_catus\n",
      "wildcat\n"
     ]
    }
   ],
   "source": [
    "# Definition refers to the feline variety of the term cat. \n",
    "# Let us determine the hyponyms of the term \"cat\", and\n",
    "# store that into a variable `types_of_cats`.\n",
    "cat = wn.synset('cat.n.01')\n",
    "types_of_cats = cat.hyponyms()\n",
    "\n",
    "# Now, let us loop through the hyponyms and see the\n",
    "# lemmas for each synset:\n",
    "for synset in types_of_cats:\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('cat.n.01'), Synset('domestic_animal.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# Note that terms like \"domestic_cat\" and \"house_cat\" are\n",
    "# more specific terms with respect to the term \"cat\", that is,\n",
    "# they are hyponyms of the word \"cat\".\n",
    "\n",
    "# Hypernym: \"a word with a broad meaning that more specific words fall\n",
    "# under; a superordinate. For example, color is a hypernym of red.\n",
    "\n",
    "# A hyponym drills down to more specificity, while a hypernym goes\n",
    "# upward toward more generality.\n",
    "\n",
    "# Example:\n",
    "#   Cat <- hypernym\n",
    "#       house_cat <- hyponym\n",
    "print(wn.synset('house_cat.n.01').hypernyms())\n",
    "\n",
    "# One way in which one may ascribe similarity between two different words\n",
    "# is to assign a score based on the distance in terms of hypernyms and\n",
    "# hyponyms. That is, how many levels up or down is a given word from\n",
    "# the other we are attempting to compare it to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet Path Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path similarity between CAR and AUTOMOBILE = \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# WordNet provides to us some metric to know how two words are related to one another.\n",
    "# The `path_similarity` function returns a score denoting how similar two\n",
    "# words are in terms of the distance between hypernyms/hyponyms.\n",
    "\n",
    "# Let us calculate this metric of similarity between words \"car\" and \"automobile\".\n",
    "\n",
    "# First, define the synsets for these terms:\n",
    "car = wn.synset('car.n.01')\n",
    "#print(car)\n",
    "automobile = wn.synset('automobile.n.01')\n",
    "\n",
    "# The path_similarity function returns a score between 0 and 1, \n",
    "# where 0 is no similarity between the hypernym/hyponym tree and \n",
    "# distance of 1 is the node which houses both of the words \n",
    "# in terms of hypernyms/hyponyms is identical.\n",
    "\n",
    "print(\"Path similarity between CAR and AUTOMOBILE = \")\n",
    "print(car.path_similarity(automobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path similarity between CAR and BOAT = \n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "# We see that \"car\" and \"automobile\" have the highest similarity possible, with a score of 1.0.\n",
    "# One of the synonyms of \"car\" is indeed \"automobile\".\n",
    "\n",
    "# Let us now take a look at the term \"car\" and \"boat\":\n",
    "boat = wn.synset('boat.n.01')\n",
    "print(\"Path similarity between CAR and BOAT = \")\n",
    "print(car.path_similarity(boat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmber similarity between CAR and AUTPMOBILE = \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# We see a lower number here. The traversal with respect to hypernyms/hyponyms \n",
    "# from car to boat is certainly at least below 1.0.\n",
    "\n",
    "# There are actually many ways in which to define distances between words.\n",
    "# let us look at the Wu-Palmber similarity metric.\n",
    "print(\"Wu-Palmber similarity between CAR and AUTPMOBILE = \")\n",
    "print(car.wup_similarity(automobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmber similarity between CAR and BOAT = \n",
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "# wup metric with \"car\" and \"boat\":\n",
    "print(\"Wu-Palmber similarity between CAR and BOAT = \")\n",
    "print(car.wup_similarity(boat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmber similarity between CAR and CAT = \n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "# wup metric with \"car\" and \"cat\":\n",
    "cat = wn.synset('cat.n.01')\n",
    "print(\"Wu-Palmber similarity between CAR and CAT = \")\n",
    "print(car.wup_similarity(cat))\n",
    "\n",
    "# We see an even lower number here, as one may expect between the terms \n",
    "# \"car\" and \"cat\" under this metric of word similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet for word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us take example sentence and find exact sense of the word \"bank\" used in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('river', 'NOUN'), ('bank', 'NOUN'), ('is', 'VERB'), ('beautiful', 'ADJ')]\n",
      "Nouns : ['river', 'bank']\n"
     ]
    }
   ],
   "source": [
    "sentence='The river bank is beautiful'\n",
    "#POS Tagging\n",
    "def pos_tag_s(sent):\n",
    "    pos_tag_list=pos_tag(word_tokenize(sent),tagset='universal')\n",
    "    return pos_tag_list\n",
    "\n",
    "pos_tag_sent=pos_tag_s(sentence)\n",
    "print(pos_tag_sent)\n",
    "\n",
    "#We try to find the exact sense of noun \"bank\" in this sentence\n",
    "chk_Noun=[]\n",
    "\n",
    "for i in pos_tag_sent:\n",
    "    if i[1]=='NOUN':\n",
    "        chk_Noun.append(i[0])\n",
    "print(\"Nouns :\",chk_Noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('river.n.01')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract synsets \n",
    "synset_1=[ss for ss in wordnet.synsets(chk_Noun[0],'n')]\n",
    "print(synset_1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract synsets \n",
    "synset_2=[ss for ss in wordnet.synsets(chk_Noun[1],'n')]\n",
    "print(synset_2,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Similarities(Probabilities) :  [[0.1111111111111111, 0.07692307692307693, 0.1, 0.09090909090909091, 0.05555555555555555, 0.08333333333333333, 0.1111111111111111, 0.09090909090909091, 0.09090909090909091, 0.0625]]\n"
     ]
    }
   ],
   "source": [
    "listpath=[]\n",
    "for i in synset_1:\n",
    "    list1=[]\n",
    "    for j in synset_2:\n",
    "       list1.append(i.path_similarity(j))\n",
    "    listpath.append(list1)\n",
    "\n",
    "print(\"Path Similarities(Probabilities) : \",listpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxvalues : [0.1111111111111111]  index list :  [0]\n"
     ]
    }
   ],
   "source": [
    "maxvalues=[]\n",
    "index_list=[]\n",
    "for x in listpath:\n",
    "    a=max(x)\n",
    "    index_list.append(x.index(a))\n",
    "    maxvalues.append(a)\n",
    "print\n",
    "print(\"maxvalues :\",maxvalues,\" index list : \",index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum probability of river matching with bank is in the sense: river.n.01\n",
      "The definition of the same is : a large natural stream of water (larger than a creek)\n",
      "The other noun bank.n.01 matching with the propability of: 0.1111111111111111\n",
      "Its definition is: sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "zipped=zip(index_list,maxvalues)\n",
    "listzip=list(zipped)\n",
    "print(\"The maximum probability of \"+chk_Noun[0]+\" matching with \"+chk_Noun[1]+\" is in the sense: \"\n",
    "      +str(synset_1[0].name())+\"\\nThe definition of the same is : \"+synset_1[0].definition()\n",
    "     +\"\\nThe other noun \" + str(synset_2[listzip[0][0]].name()) + \" matching with the propability of: \"+str(listzip[0][1])\n",
    "      +\"\\nIts definition is: \" + synset_2[listzip[0][0]].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywsd in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: wn==0.0.23 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pywsd) (1.3.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pywsd) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pywsd) (1.21.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from pywsd) (3.6.2)\n",
      "Requirement already satisfied: regex in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk->pywsd) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk->pywsd) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk->pywsd) (0.15.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk->pywsd) (4.48.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "Warming up PyWSD (takes ~10 secs)... C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context-1: I went to the bank to deposit my money\n",
      "Sense: Synset('depository_financial_institution.n.01')\n",
      "Definition :  a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "took 14.252366304397583 secs.\n"
     ]
    }
   ],
   "source": [
    "#Install pywsd  \n",
    "!pip install pywsd  \n",
    "   \n",
    "#Import functions  \n",
    "from pywsd.lesk import simple_lesk  \n",
    "sentences = ['I went to the bank to deposit my money',  \n",
    "'The river bank was full of dead fishes']  \n",
    "# calling the lesk function and printing results for both the sentences  \n",
    "print (\"Context-1:\", sentences[0])  \n",
    "answer = simple_lesk(sentences[0],'bank')  \n",
    "print (\"Sense:\", answer)  \n",
    "print (\"Definition : \", answer.definition())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context-2: The river bank was full of dead fishes\n",
      "Sense: Synset('bank.n.01')\n",
      "Definition :  sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "print (\"Context-2:\", sentences[1])  \n",
    "answer = simple_lesk(sentences[1],'bank')  \n",
    "print (\"Sense:\", answer)  \n",
    "print (\"Definition : \", answer.definition())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = ['The workers at the plant were overworked',\n",
    " \n",
    "'The plant was no longer bearing flowers',\n",
    " \n",
    "'The workers at the industrial plant were overworked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context-1: The workers at the plant were overworked\n",
      "Sense: Synset('plant.v.06')\n",
      "Definition :  put firmly in the mind\n"
     ]
    }
   ],
   "source": [
    "# calling the lesk function and printing results  \n",
    "print (\"Context-1:\", new_sentences[0])  \n",
    "answer = simple_lesk(new_sentences[0],'plant')  \n",
    "print (\"Sense:\", answer)  \n",
    "print (\"Definition : \", answer.definition()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context-3: The plant was no longer bearing flowers\n",
      "Sense: Synset('plant.v.01')\n",
      "Definition :  put or set (seeds, seedlings, or plants) into the ground\n"
     ]
    }
   ],
   "source": [
    "print (\"Context-3:\", new_sentences[1])  \n",
    "answer = simple_lesk(new_sentences[1],'plant')  \n",
    "print (\"Sense:\", answer)  \n",
    "print (\"Definition : \", answer.definition())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
